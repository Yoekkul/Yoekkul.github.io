---
layout: post
title:  "Visualizing parametric architectural models in Virtual Reality, generated with Grasshopper"
date:   2023-11-17 12:01:40 +0100
categories: xr
---
<span style="color:darkgray">tldr: cool VR visualization of architecture: [source](https://github.com/Yoekkul/owl-XR)</span>

The toolbox of a modern architect contains software which surpasses the technique of extruding elemental shapes. It allows the creation of organic and programmatic architecture.
Examples of such work can be found in [Frank Gehry's Guggenheim Museum](https://www.guggenheim-bilbao.eus/en/did-you-know/frank-gehry), built with the help of custom aerospace design software, Santiago Calatrava's bridges and [train stations](https://howtorhino.com/rhino-grasshopper-tutorials/calatrava-train-station/), [Renzo Piani's Kansai airport](https://www.awn.it/index.php?option=com_content&view=article&id=7057) and many more.

![Examples of organic architecture](/assets/images/grasshopper_post/calatrava.jpg)
<span style="color:darkgray">Source: wikimedia</span>

The CAD software Rhino3d and especially its plugin Grasshopper, provide tools to create  such "parametric" architecture. Here basic geometry is processed through a custom node-based programming language which, given input parameters alters them through a directed acyclic graph of nodes.

![How Grasshopper looks](/assets/images/grasshopper_post/gh_samples.jpg)
<span style="color:darkgray">Source: grasshopper3d.com</span>

The goal of my project is to provide a tool which enables architects to tighten the feedback loop between design and immersive visualization using the grasshopper parametric design tool, without the need to construct intermediate physical model for each small modification in parameters. 

Building on the [StereoKit](https://stereokit.net/) framework for XR applications allowed me to quickly create a working prototype. The framework is built on top of OpenXR, which allows me to develop a single application able to run on VR devices (such as the Oculus), MR devices (such as the Hololens 2) as well as smartphones. To integrate it with Grasshopper I created 2 new nodes for its graphical programming language. These provide respectively an input "slider" having from, to and step parameters responding to user actions (a pinch or grab gesture result in change of the output) as well as a "send" node, which takes the geometry generated through the graph, and passes it via a TCP network connection to any connected XR clients.  

![Small example of components assembled together](/assets/images/grasshopper_post/alltogethernow.png)
<span style="color:darkgray">The two new components in a small example graph: The slider (top left) outputs the value 5, which is then multiplied by a constant 10 (by the multiplication block). This gets passed as an input to a mesh generator, which sends its output to any connected client</span>

Communication between the different components works as follows: When one of my newly created grasshopper components gets added to a design graph it starts a new TCP server, listening for requests. When a client application (running for instance on a Virtual Reality headset) starts it initially sends a series of UDP pings onto the local network (currently communication only works between devices on the same LAN). The previously started Grasshopper server then responds to these pings, letting the client know where to connect. When this is done a new TCP connection is initiated by the client. Whenever an update to the geometry generated by Grasshopper occurs it gets serialized in JSON format and sent to all connected clients (yep, there can be multiple clients connected at once =D ). The opposite process occurs whenever a client registers an action by an user (such as pinching or grabbing). This action gets sent back to the Grasshopper server, which then makes it available to the slider parameter.

![How Grasshopper looks](/assets/images/grasshopper_post/large_sample.png)
<span style="color:darkgray">Bringing all together, on the right Rhino3d generates a complex model, on the other side a VR emulator shows its result</span>


